# ğŸ’¾ DesafÃ­o TÃ©cnico â€“ Procesamiento de archivo

Este proyecto tiene como objetivo procesar un archivo de gran tamaÃ±o (`CLIENTES_IN_0425.dat`), validar su contenido y almacenar los registros vÃ¡lidos en una base de datos SQL Server. El servicio estÃ¡ preparado para correr en un pod de Kubernetes con recursos limitados.

## ğŸ§° TecnologÃ­as utilizadas

- **Node.js + TypeScript**
- **SQL Server** (para almacenamiento de datos)
- **Swagger** (para documentaciÃ³n de endpoints)
- **Kubernetes** (ambiente objetivo)
- **Logger personalizado** (para control de uso de memoria y trazabilidad)

## â–¶ï¸ EjecuciÃ³n del procesamiento

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/worldsys-challenge.git
cd worldsys-challenge
```

### 2. Instalar dependencias

```bash
npm install
```

### 4. Crear la base de datos y tabla (si no existen)

PodÃ©s ejecutar el siguiente script SQL en tu servidor de SQL Server:

```bash
CREATE DATABASE clientes;
GO

USE clientes;
GO

CREATE TABLE Clientes (
  Id INT IDENTITY(1,1) PRIMARY KEY,
  NombreCompleto VARCHAR(100),
  DNI VARCHAR(20),
  Estado VARCHAR(50),
  FechaIngreso DATE,
  EsPEP BIT,
  EsSujetoObligado BIT,
  FechaCreacion DATETIME DEFAULT GETDATE()
);
```

TambiÃ©n podÃ©s ejecutar el siguiente comando para verificar que la tabla exista (y crearla si hace falta):

```bash
npm run check
```

### 4. Configurar variables de entorno

Crear un archivo .env en la raÃ­z del proyecto con la configuraciÃ³n de conexiÃ³n a la base de datos:

```bash
DB_USER=sa
DB_PASSWORD=yourStrong(!)Password
DB_SERVER=localhost
DB_NAME=clientes
```

### 5. Ejecutar el procesador de archivo

Para ejecutar el procesamiento:

```bash
npm run start
```

Se mostrarÃ¡ un resumen por consola con las estadÃ­sticas de procesamiento, uso de memoria, y lÃ­neas vÃ¡lidas/errÃ³neas.

### 6. ğŸ“˜ Swagger

Si bien la soluciÃ³n principal es un script para procesamiento batch, tambiÃ©n se incluye el endpoint health documentado con Swagger. Esto facilita la futura ampliaciÃ³n del proyecto.

### 6. ğŸ“Œ ğŸ“ˆ Ideas para escalar la soluciÃ³n a futuro

#### ğŸ§µ 1. ParalelizaciÃ³n por bloques

Dividir el archivo en chunks y usar `worker_threads` o `child_process` para procesarlos en paralelo.

#### ğŸ—ƒï¸ 2.InserciÃ³n por lote

Agrupar registros vÃ¡lidos y hacer `bulk insert` para reducir llamadas a la base de datos.

#### â˜ï¸ 3. Microservicio escalable

- Subida del archivo a un bucket (ej. S3)

- MÃºltiples pods paralelos en Kubernetes leyendo y procesando partes del archivo

#### ğŸ“¦ 4. OptimizaciÃ³n de base de datos

- Uso de Ã­ndices

- Procedimientos almacenados

- Transacciones por lote

#### ğŸ“Š 5. Monitoreo real

Agregar:

- Prometheus + Grafana

- New Relic o Datadog

- ELK stack para logs centralizados

### âš™ï¸ ğŸ§  Escalado distribuido con Apache Kafka

Para entornos con alto volumen de archivos o mÃºltiples fuentes simultÃ¡neas, se puede escalar la soluciÃ³n usando Apache Kafka.

### ğŸ¯ Â¿Por quÃ© Kafka?

- Desacopla lectura y escritura

- Tolerancia a fallos

- Escalado horizontal con mÃºltiples consumidores

- Procesamiento concurrente

- Persistencia temporal de eventos

- IntegraciÃ³n con pipelines externos

### Consideraciones

- Mayor complejidad de infraestructura

- Ãštil solo en escenarios de alto volumen o streaming
